# Artificial Intelligence Assignments  

## Overview  
This repository contains **assignments and projects** from **CS 471: Introduction to Artificial Intelligence** at the **University of Oregon**. The coursework covers **search algorithms, multi-agent decision-making, and reinforcement learning**, applying these techniques to **Pacman AI agents**.

## Projects 📂  

### **Project 1 – Search Algorithms (Pathfinding & Heuristics)**  
📌 **Description:**  
Implemented **fundamental search algorithms** for **Pacman navigation**. These included classic uninformed and informed search strategies to optimize movement in a maze environment.

🔹 **Key Features:**  
✅ **Depth-First Search (DFS)** – Explores paths to find solutions quickly.  
✅ **Breadth-First Search (BFS)** – Guarantees shortest path in an unweighted maze.  
✅ **Uniform Cost Search (UCS)** – Uses cost functions to determine optimal paths.  
✅ **A* Search Algorithm** – Implements heuristics for more efficient search.  
✅ **Corners & Food Problems** – Extended search to solve more complex problems.  

---

### **Project 2 – Multi-Agent Search (Minimax, Alpha-Beta Pruning, Expectimax)**  
📌 **Description:**  
Developed **intelligent agents** for Pacman, incorporating **game theory concepts** to optimize decision-making against adversarial opponents (ghosts).

🔹 **Key Features:**  
✅ **Reflex Agent** – A basic rule-based AI to respond to the environment.  
✅ **Minimax Algorithm** – Implemented **adversarial search** for strategic decision-making.  
✅ **Alpha-Beta Pruning** – Optimized minimax by reducing unnecessary computations.  
✅ **Expectimax Algorithm** – Introduced **probabilistic decision-making** for uncertain environments.  
✅ **Custom Evaluation Functions** – Designed heuristics to enhance agent performance.  

---

### **Project 3 – Reinforcement Learning (MDPs & Q-Learning)**  
📌 **Description:**  
Implemented **reinforcement learning techniques**, including **Markov Decision Processes (MDPs)** and **Q-learning**, to enable **Pacman to learn from experience**.

🔹 **Key Features:**  
✅ **Value Iteration** – Used **Bellman equations** to compute optimal policies.  
✅ **Policy Optimization** – Tuned discount factors & rewards to shape behavior.  
✅ **Q-Learning Algorithm** – Enabled **Pacman to learn action-reward mappings**.  
✅ **Epsilon-Greedy Strategy** – Balanced exploration and exploitation.  
✅ **Approximate Q-Learning** – Used **feature-based learning** to generalize policies.  

---

## Lessons Learned 💡  
- **Project 1**: Strengthened understanding of **graph search algorithms and heuristics**.  
- **Project 2**: Gained experience in **game AI, adversarial search, and optimization**.  
- **Project 3**: Developed skills in **reinforcement learning and MDP-based decision-making**.  

## Author ✨  
👨‍💻 **Nikhar Ramlakhan**  
📚 **CS 471/571 - Introduction to Artificial Intelligence** | University of Oregon  
📝 **Instructor:** Prof. Thanh Nguyen

---

## License  
This repository contains coursework projects and is intended for **educational purposes only**.

